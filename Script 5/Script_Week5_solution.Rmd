---
title: "Script 5: Correlations Part 2"
author: "Ana-Maria Plesca"
date: "2023-04-11"
output:
  html_document:
    toc: true
---

# Introduction

Welcome to the fifth week of statistics with R. This week we will continue learning about correlations, but you will be the one doing most of the work.I am still strongly recommending you to take a look at Chapter 6 in Andy Field's book Discovering Statistics with R. 

# Learning objectives

1. Gain more confidence in using difference correlation tests.
2. Enrich scatterplot-drawing skills.
3. Achieve a very good understanding of bivariate correlations.

# Script prep

Loading packages

```{r message=FALSE, warning=FALSE}
library(Hmisc)
library(ggplot2)
library(polycor)
library(tidyverse)
library(nortest)
library(Rmisc)
options(scipen = 999)
```

Setting up the working directory

```{r}
setwd("~/Desktop/Stats planning/Script 5") # please adjust this path 
```

# Bivariate correlation

We'll have a look at another example of bivariate correlation, using **exam anxiety data coming from 103 students** (Train your reflex to keep in mind the size of the sample you are working with - this helps you figure out which statistical tests are better suited for your data).

```{r}
examAnxiety <- haven::read_sav("Exam Anxiety.sav")
examAnxiety
```

The variables we will be working with are:

- Time spent revising for the exam (expressed in hours) - see column **Revise**
- Exam performance (expressed in percentages) - see column **Exam**
- Exam anxiety (expressed in scores out of 100) - see column **Anxiety**
- Gender -see column **Gender**

Note: The **Code** column represents the participant number.

As you know already, before we even begin conducting our analysis, we need to specifically state our hypotheses about the data.

1) As anxiety increases, exam performance will decrease.
2) The more time was spent revising, the more the exam performance will increase.

What does this tell you about the hypotheses? Think about this to prepare for the correlation tests.


## Scatterplots and regression lines

By now you already know how to draw scatterplots both with `ggplot()` and without (simply using the `plot()` function call and supplying two numerical variables). We will now add to your scatterplot-related knowledge a new element: **a regression line**.

When we add such a regression line to a `ggplot()` scatterplot, we in fact add a *smoothing* element to it using the `geom_smooth()` function. What this does is adds a line that summarizes the relationship between the variables, it smooths out all data points into a line. We won't yet go into the details of regression, but for now, think of a regression line, as a summary of the relationship between two variables.

Let's put this into practice.

### Example: Plotting a scatterplot of anxiety by exam performance 

To create scatterplots you essentially need to add the `geom_point()` layer to the `ggplot()` geometric structure. 
We will add the regression line that summarizes the relationship between anxiety and exam performance with the `geom_smooth()` layer, and the argument: `method = lm`. We are instructing the `geom_smooth` layer to add a line, and the chosen method is that of a linear model (abbreviated as `lm`)

```{r message=FALSE, warning=FALSE}
ggplot(examAnxiety, aes(Exam, Anxiety))+
geom_point(size = 3) +
geom_smooth(method = "lm") +
labs(x = "Exam Performance (%)", y = "Exam Anxiety",
     title = "Relationship between exam anxiety and exam performance") 
```

The regression line is surrounded by the 95% confidence interval (the grey area). If you want to keep the regression line only, please supply one more argument to the geom_smooth() layer: `se = F` (which
is short for 'standard error = False'). 

Furthermore, you can adjust the color of the regression line, to make it stand out more.

```{r message=FALSE, warning=FALSE}
ggplot(examAnxiety, aes(Exam, Anxiety))+
geom_point(size = 3) +
geom_smooth(method = "lm", color = "red", se = F) + # changed the color of the regression line + switched off CIs based on standard error
labs(x = "Exam Performance (%)", y = "Exam Anxiety",
     title = "Relationship between exam anxiety and exam performance") 
```

What does this plot tell you? How would you summarize the relationship between exam anxiety and exam performance?

Solved: This plot describes a negative, fairly strong relationship. We have no correlation coefficient yet to confirm this statement. However, the closer the data points are to the regression line, the stronger their relationship. It seems to be the case that the higher the anxiety, the poorer the exam performance.

### Task 1: Plot a scatterplot of revision time by exam performance

It's your turn to "draw" a scatterplot describing the relationship between revision time and exam performance. I advise you to not copy & paste the code above. Try to recreate it yourself, as this will help you understand the process.

To complete this task, please add:

- a green-coloured regression line
- a regression line without CI
- labels for the x and y axes and a meaningful title
- a description of the relationship between the two variables

```{r message=FALSE, warning=FALSE}
ggplot(examAnxiety, aes(Exam, Revise))+
  geom_point(size = 2)+
  geom_smooth(method = "lm", color = "green", se = F) +
  labs(x = "Exam Performance (%)", y = "Revision",
     title = "Relationship between revision done for the exam and exam performance")
```

The amount of revision and exam performance seem to be very closely correlated, as well as described by a positive relationship. The more revision was done for the exam, the better the performance was.


### How to use the regression line to predict scores?

In SPSS, the value of the regression line is conveniently provided with the plot and you had no issue computing the predicted anxiety score for an exam score of 80. How do we do that in R? Don't worry if what follows will feel a bit too complicated. At this step, you only need to understand how we can achieve this information with R.

**Step 1: Building a linear model**

We will use the `lm()` function to build a linear regression model. At this stage we are using it to understand the relationship between exam performance and anxiety.

The arguments (parameters) of `lm()` function:

formula – The formula to be applied for the linear model, it should be in the form y (dependent variable - e.g., exam performance) ~ x1 (independent variable - e.g., anxiety score) 
data – The object containing your data - usually a dataframe

We want to understand how exam performance is impacted by anxiety and so we will model exam performance as a function of anxiety using the formula `Exam ~ Anxiety`

```{r}
examAnxiety_lm <- lm(Anxiety ~ Exam, data = examAnxiety)
examAnxiety_lm
```

**Step 2: Extracting the estimated values of the linear model**

The result of fitting the linear model to the data are two estimated values:

1) The intercept - in our case the average estimated anxiety with a value of `90.8682`
2) A slope - tells you how much change in the y-variable (anxiety) is caused by a unit change in x-variable. (exam score) `-0.2921`.

**Step 3: Use the linear model equation and the estimated values from the linear model**

Here's an exemplified version of the linear model equation:

<p class="alert alert-info">
Yi = β0 + β1*Xi 
</p>

We are trying to predict Yi, the anxiety of a person i, based on their exam score Xi.  
β0 represents the overall anxiety (the intercept) and β1 the slope estimated value associated with exam score

For an exam score of 80 (that is, Xi = 80), what is the predicted anxiety score? Let's use the formula and replace the value we already know from the model.

```{r}
y = 90.8682 + -0.2921 * 80

y
```

The predicted anxiety score of a person who obtained an 80% exam performance score is 67.5002.

### Task 2: Predict the anxiety 

It's your turn now. What's the predicted anxiety score for a person who achieved a 20 exam score?

```{r}
y = 90.8682 + -0.2921 * 20
y
```

- The predicted anxiety score for an exam performance of 20 is 85.02

What can you lean from these values? Put them in relation to the scatterplot you've drawn.

- These values confirm our intuitions we have build based on the scatterplots. In the presence of a high level of anxiety, the exam performance drops. By contrast, higher exam performance percentages were associated with lower anxiety scores.

## Task 3: Testing for normality

Our goal is still to compute correlation analyses between exam performance and anxiety, as well as between exam performance and revision. In the next step, we need to test for the assumption of normality so that we can decide what kind of correlation analysis we will conduct.

For each of the following three tasks, please:

1) Draw histograms to show the distribution of the variables. Use either the `hist()` function or the `ggplot()` function. 
2) Conduct the appropriate normality test. Keep in mind the sample size (N = 103) when you make the decision. If you need a refresher, take a look at the second week's script.
3) Report the results of each test

### Task 3.1. : Test anxiety scores for normality

**Histogram describing the distribution of normality scores**

Option 1:

```{r}
hist(examAnxiety$Anxiety)
```

Option 2:

```{r}
ggplot(data = examAnxiety, aes(x = Anxiety))+
  geom_histogram(aes(y = ..density..),color = "blue", fill = "lightblue", bins = 10)+
  geom_density(color = "red")        
```
The anxiety scores are strongly negatively skewed. In other words, high scores of anxiety are highly frequent, whereas low anxiety scores are rare (infrequent).

**Conducting a normality-test**

Since this is a large sample, we will conduct a **Lilliefors-corrected Kolmogorov–Smirnov test**

```{r nor-test-anxiety}
nortest::lillie.test(examAnxiety$Anxiety)
```

The K-S normality test yielded a significant result *D* = .15, *p* < .001, indicating that the distribution of the anxiety scores differs significantly from normality.


### Task 3.2. : Test exam performance for normality

**Histogram describing the distribution of normality scores**

Option 1:

```{r}
hist(examAnxiety$Exam)
```

Option 2:

```{r}
ggplot(data = examAnxiety, aes(x = Exam))+
  geom_histogram(aes(y = ..density..),color = "blue", fill = "lightblue", bins = 10)+
  geom_density(color = "red")        
```

The distribution of the exam performance percentages looks mixed, though with a tendency towards a negative skew. 

**Conducting a normality-test**

Since this is a large sample, we will conduct a **Lilliefors-corrected Kolmogorov–Smirnov test**

```{r nor-test-exam}
nortest::lillie.test(examAnxiety$Exam)
```
The K-S normality test yielded a significant result *D* = .13, *p* < .001, indicating that the distribution of the exam performance percentage scores differs significantly from normality.

### Task 3.3. : Test revision for normality

**Histogram describing the distribution of normality scores**

Option 1:

```{r}
hist(examAnxiety$Revise)
```

Option 2:

```{r}
ggplot(data = examAnxiety, aes(x = Revise))+
  geom_histogram(aes(y = ..density..),color = "blue", fill = "lightblue", bins = 10)+
  geom_density(color = "red")        
```

The time spent revising is positively skewed, with highly frequent low values are highly frequent and infrequent high values.

**Conducting a normality-test**

Since this is a large sample, we will conduct a **Lilliefors-corrected Kolmogorov–Smirnov test**

```{r nor-test-revise}
nortest::lillie.test(examAnxiety$Revise)
```

The K-S normality test yielded a significant result *D* = .17, *p* < .001, indicating that the distribution of the revision scores differs significantly from normality.


## Task 4: Choosing the appropriate correlation test

Based on the results of the previous tasks, you have hopefully reached the conclusion that none of the three variables are normally distributed. Choose the correlation test according to the following criteria:

1) Data is not normally distributed
2) Your sample size is large (N = 103)

Don't forget the hypotheses we've come up in the beginning for each of the two analyses we want to conduct. These are essential for running the analyses:

- **H1:** As *anxiety increases*, *exam performance* will *decrease.* (Anxiety + exam performance correlation)

- **H2:** The *more time was spent revising*, the more the *exam performance will increase*. (Revision + exam performance correlation)

Since none of the variables are normally distributed, I chose to conduct correlation analyses using the Spearman's rho. Spearman is a non-parametric test and does not require meeting the normality assumption.

```{r corr_anxiety_exam}
# conduct the anxiety-by-exam performance correlation here - one-tailed test + negative relationship (as one increases, one decreases)

cor.test(examAnxiety$Exam, examAnxiety$Anxiety, alternative = "less", method = "spearman")
```

<div class="alert alert-warning" role="alert">
What does that warning mean?
The spearman correlation coefficient works with the rank of values and so the correlation test ignores the same ranks to find the p-values. As a result we get this warning: “Cannot compute exact p-value with ties”. Don't worry about this.</div>

Please report the results of the anxiety-by-exam performance correlation here:

The analysis revealed a reliable negative correlation between exam performance and exam
anxiety (Spearman's ρ (one-tailed) = -.40, p < .001).

```{r corr_revision_exam}
# conduct the anxiety-by-exam performance correlation here - one-tailed test + positive relationship (as one increases, the other one increases too)

cor.test(examAnxiety$Exam, examAnxiety$Revise, alternative = "greater", method = "spearman")
```
 Please report the results of the revision-by-exam performance correlation here:
The analysis revealed a reliable positive correlation between exam performance and amount of revision done for the exam (Spearman's ρ (one-tailed) = .35, p < .001).

## Task 5: Compute the R^2 value

In the last script we have learned how to compute the **coefficient of determination, R^2**. It indicates the amount of variance in one variable that is accounted for/shared by another variable.


### Task 5.1.: Compute the coefficient of determination, R^2 for anxiety and exam performance

```{r r2_exam_anxiety}
cor(examAnxiety$Exam, examAnxiety$Anxiety)^2
```

What does the value you have computed mean? Interpret it please.

The obtained R^2 for exam performance and anxiety is 0.194 and it indicates that anxiety accounts for 19.4 percent of the variance in exam performance. Remember that if you multiply the result of the R^2 you can express the result in percentages

### Task 5.2.: Compute the coefficient of determination, R^2 for revision and exam performance

```{r r2_exam_revision}
cor(examAnxiety$Exam, examAnxiety$Revise)^2
```

What does the value you have computed mean? Interpret it please.
The obtained R^2 for exam performance and revision is 0.157 and it indicates that revision accounts for 15.7 percent of the variance in exam performance. Remember that if you multiply the result of the R^2 you can express the result in percentages

# Correlation continued

Here comes one more correlation exercise based on the the data file "Mydata.sav". It shows made-up data from managers and from employees about their number of friends, date of birth, their alcohol consumption (in units), their neuroticism scores (the higher the score, the more neurotic), and their annual income in GBP.

Group 1 is represented by managers, Group 2 by employees

```{r}
employee_manager_data <- haven::read_sav("Mydata.sav")
```

Take a look at the data

```{r}
head(employee_manager_data)
```

## Task 1: Plot a bar graph 

- Plot the mean alcohol consumption on the y-axis, 
- Plot the group (managers -1 and employees -2) on the x-axis
- Include error bars (95 percent condence intervals of each mean) - remember which function you need to use?
- Interpret the graph

Step 1: Making sure the Group variable is a factor.

```{r}
employee_manager_data$Group <- as.factor(employee_manager_data$Group)

# You could also recode the factor to be more informative
employee_manager_data <- employee_manager_data %>% 
  mutate(Group = recode_factor(Group,
                               "1" = "Manager",
                               "2" = "Employee"))
employee_manager_data
```

Step 2: Computing summary statistics to add error bars representing 95% CIs

```{r}
# We don't care whether this was a within-subjects survey, so we will simply use summarySE()

employee_manager_data_summary <- summarySE(employee_manager_data, measurevar = "Alcohol", groupvars = "Group")
employee_manager_data_summary
```

```{r}
ggplot(employee_manager_data_summary, aes(x = Group, y = Alcohol, fill = Group))+
  geom_bar(position = "dodge", stat = "summary", fun = "mean")+ 
    geom_errorbar(aes(ymin=Alcohol-ci, ymax=Alcohol+ci), 
                  width=.2,                              
                  position=position_dodge(.9))+
  labs(x = "Film", y = "Average alcohol consumption", fill = "Group", 
       title = "Average alcohol consumption by group")+ 
  scale_fill_brewer(palette = "Reds")
```
Interpretation: The bar graph shows that on average employees (M=21.2) consume more alcohol than managers (M =14.7). The 95 percent CIs are  wider for the managers than for the employees - this could suggest that the true average alcohol consumption for managers could be quite different from the one that we observed.

## Task 2: Plot a scatterplot

- Plot the alcohol consumption on the y-axis
- Plot the on the neuroticism (x-axis) 
- The plot should be grouped by Group, that is by manager / employee (We used the layer facet_wrap() to achieve this. It is up to you to remember/figure out how to do it. (We've done this before)
- Include the regression line 
- Describe the relationship between the two variables

```{r message=FALSE, warning=FALSE}
ggplot(employee_manager_data, aes(Neurotic, Alcohol))+
geom_point(size = 3) +
geom_smooth(method = "lm", color = "red", se = F) + 
labs(x = "Neuroticism score", y = "Alcohol consumption",
     title = "Relationship between exam anxiety and exam performance") +
facet_wrap(~Group)
```

There is a negative relationship for employees: As the neuroticism score increases, the alcohol intake score decreases. In other words, the less neurotic an employee is, the more alcohol is consumed.

There is a positive fairly strong relationship for managers: As the neuroticism score increases, the alcohol consumption increases too. In other words, the more neurotic a manager is, the higher the alcohol intake.

## Task 3: Is there a reliable correlation between alcohol consumption and neuroticism?

- State your hypothesis and its type.
- Run normality analyses (keep in mind the sample size)
- Run a correlation analysis (keep in mind the sample size and the type of data)

**Stating the hypothesis**

Hypothesis: There is a reliable correlation between alcohol consumption and neuroticism. This is a two-tailed hypothesis

**Assessing normality of distribution of alcohol consumption**

```{r}
hist(employee_manager_data$Alcohol)
```
Since our sample size is rather small, we can use the Shapiro-Wilk test to check whether the data is normally distributed.

```{r}
shapiro.test(employee_manager_data$Alcohol)
```

The data in the alcohol variable does not deviate significantly from normality (*W*(20) = .95, *p* = .48). 

Note: W - shapiro-wilk test coefficient, (20) - sample size

**Assessing normality of distribution of neuroticism scores**

```{r}
hist(employee_manager_data$Neurotic)
```
Since our sample size is rather small, we can use the Shapiro-Wilk test to check whether the data is normally distributed.

```{r}
shapiro.test(employee_manager_data$Neurotic)
```
The data in the alcohol variable does not deviate significantly from normality (*W*(20) = .97, *p* = .85). 

Note: W - shapiro-wilk test coefficient, (20) - sample size

**Run a correlation analysis**

Since the normality parameter is met, we have green lights to conduct Pearson's bivariate correlation. Since our hypothesis is not directional, which means we don't expect necessarily a positive or a negative effect, we will run a two-tailed test.

```{r}
cor.test(employee_manager_data$Alcohol, employee_manager_data$Neurotic, alternative = "two.sided",
         method = "pearson")
```
The results show that there is no reliable correlation between alcohol and neuroticism (r = -.057, p > .8).

## Extra tasks (not obligatory)

- Build subsets for managers and employees
- Run the correlation analyses again. What conclusion have you reached?


